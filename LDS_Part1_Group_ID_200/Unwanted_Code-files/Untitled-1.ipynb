{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import requests\n",
    "import time\n",
    "from decimal import Decimal  # Import the Decimal class\n",
    "\n",
    "#Write to my db\n",
    "# Connection string\n",
    "server = 'tcp:lds.di.unipi.it'\n",
    "username = 'Group_ID_200'\n",
    "password = '89VIG10K'\n",
    "database = 'Group_ID_200_DB'\n",
    "connectionString = 'DRIVER={ODBC Driver 17 for SQL Server};SERVER=' + server + ';DATABASE=' + database + ';UID=' + username + ';PWD=' + password\n",
    "\n",
    "\n",
    "# Assuming you have a SQL Server connection\n",
    "# Connect to the SQL Server database\n",
    "conn = pyodbc.connect(connectionString)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Assuming 'Geography' is your table name\n",
    "query = \"SELECT latitude, longitude FROM Geography WHERE city IS NULL OR state IS NULL\"\n",
    "cursor.execute(query)\n",
    "\n",
    "# Fetch all records at once\n",
    "records = cursor.fetchall()\n",
    "# records = records[20:100]\n",
    "print(len(records))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to insert data using bulk insert\n",
    "def bulk_insert_data(conn, cursor, table_name, data):\n",
    "    columns = ', '.join(data[0].keys())\n",
    "    placeholders = ', '.join(['?'] * len(data[0]))\n",
    "\n",
    "    # Prepare the values as a list of tuples\n",
    "    values = [tuple(row.values()) for row in data]\n",
    "\n",
    "    # Build the bulk insert query\n",
    "    bulk_insert_query = f'INSERT INTO {table_name} ({columns}) VALUES ({placeholders});'\n",
    "\n",
    "    # Execute the bulk insert query\n",
    "    cursor.executemany(bulk_insert_query, values)\n",
    "    conn.commit()\n",
    "\n",
    "# Function to insert data into the database\n",
    "def insert_data_with_ID(conn, cursor, id_dict, table_name, key_dict):\n",
    "    key_tuple = tuple(key_dict.values())\n",
    "    if key_tuple not in id_dict:\n",
    "        id_dict[key_tuple] = next(iter(key_dict.values()))\n",
    "        columns = ', '.join(key_dict.keys())\n",
    "        placeholders = ', '.join(['?'] * len(key_dict))\n",
    "        insert_query = f'INSERT INTO {table_name} ({columns}) VALUES ({placeholders});'\n",
    "\n",
    "        cursor.execute(insert_query, list(key_dict.values()))\n",
    "        conn.commit()\n",
    "\n",
    "def insert_data_without_ID(conn, cursor, table_name, key_dict):\n",
    "    columns = ', '.join(key_dict.keys())\n",
    "    placeholders = ', '.join(['?'] * len(key_dict))\n",
    "    insert_query = f'INSERT INTO {table_name} ({columns}) VALUES ({placeholders});'\n",
    "    select_query = f'SELECT TOP 1 * FROM {table_name};'\n",
    "\n",
    "    # Execute the INSERT query\n",
    "    cursor.execute(insert_query, list(key_dict.values()))\n",
    "    conn.commit()\n",
    "\n",
    "    # Execute the SELECT query to fetch the last inserted row's ID\n",
    "    cursor.execute(select_query)\n",
    "    id_generated = cursor.fetchone()[0]\n",
    "\n",
    "    # Return the last inserted row's ID\n",
    "    return id_generated\n",
    "\n",
    "def get_or_insert_id(conn, cursor, id_dict, table_name, key_dict):\n",
    "    key_tuple = tuple(key_dict.values())\n",
    "    if key_tuple in id_dict:\n",
    "        return id_dict[key_tuple]\n",
    "    else:\n",
    "        last_inserted_id = insert_data_without_ID(conn, cursor, table_name, key_dict)\n",
    "        id_dict[key_tuple] = last_inserted_id\n",
    "        return last_inserted_id\n",
    "\n",
    "date_mapping = parse_dates_xml('dates.xml')\n",
    "\n",
    "# Read and process Police.csv\n",
    "with open('Police-9.csv', 'r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    next(reader)  # Skip the header row\n",
    "\n",
    "    # List of table names in your database\n",
    "    table_names = ['Custody', 'Geography', 'Gun', 'Date', 'Incident', 'Partecipant']\n",
    "\n",
    "    # Clean the tables by deleting all records\n",
    "    for table_name in table_names:\n",
    "        cursor.execute(f'DELETE FROM {table_name}')\n",
    "        conn.commit()\n",
    "        \n",
    "    # List to store data for bulk insert\n",
    "    bulk_data = []\n",
    "\n",
    "    for row in reader:\n",
    "        custody_id, participant_age_group, participant_gender, participant_status, participant_type, latitude, longitude, gun_stolen, gun_type, incident_id, date_fk = row\n",
    "\n",
    "        gun_stolen_bool = 1 if row[\"gun_stolen\"] == 'Stolen' else 0\n",
    "        gun_key_dict = {\"is_stolen\": gun_stolen_bool, \"gun_type\": row['gun_type']}\n",
    "        gun_id = get_or_insert_id(conn, cursor, gun_id_dict, 'Gun', gun_key_dict)\n",
    "\n",
    "        partecipant_key = {\n",
    "            \"age_group\": row['participant_age_group'],\n",
    "            \"gender\": row['participant_gender'],\n",
    "            \"type\": row['participant_type'],\n",
    "            \"status\": row['participant_status']\n",
    "        }\n",
    "        partecipant_id = get_or_insert_id(conn, cursor, partecipant_id_dict, 'Partecipant', partecipant_key)\n",
    "\n",
    "        # Get location information from latitude and longitude\n",
    "        latitude, longitude = float(row['latitude']), float(row['longitude'])\n",
    "        location_info = get_location_info(latitude, longitude)\n",
    "        city = location_info[\"city\"]\n",
    "        state = location_info[\"state\"]\n",
    "        country = \"United States\"\n",
    "        continent = \"North America\"\n",
    "        geo_key = {\n",
    "            \"latitude\": str(latitude), \"longitude\": str(longitude), \"city\": city, \"state\": state, \"country\": country,\n",
    "            \"continent\": continent\n",
    "        }\n",
    "        geo_id = get_or_insert_id(conn, cursor, geo_id_dict, 'Geography', geo_key)\n",
    "\n",
    "        date_id = int(row['date_fk'])\n",
    "        date_value = date_mapping[date_id]\n",
    "        date, day, month, year, quarter, day_of_week = compute_date_data(date_value)\n",
    "        date_key = {\n",
    "            \"date_id\": date_id, \"the_date\": date, \"the_day\": day, \"the_month\": month, \"the_year\": year, \"quarter\": quarter,\n",
    "            \"day_of_week\": day_of_week\n",
    "        }\n",
    "        insert_data_with_ID(conn, cursor, date_id_dict, \"Date\", date_key)\n",
    "\n",
    "        incident_id = int(row['incident_id'])\n",
    "        incident_key = {\"incident_id\": incident_id}\n",
    "        insert_data_with_ID(conn, cursor, incident_id_dict, \"Incident\", incident_key)\n",
    "\n",
    "        custody_id = row['custody_id']\n",
    "        custody_key = {\n",
    "            \"custody_id\": custody_id, \"partecipant_id\": partecipant_id, \"gun_id\": gun_id, \"geo_id\": geo_id,\n",
    "            \"date_id\": date_id, \"crime_gravity\": compute_crime_gravity(row), \"incident_id \": incident_id\n",
    "        }\n",
    "        insert_data_with_ID(conn, cursor, custody_id_dict, 'Custody', custody_key)\n",
    "\n",
    "        # Append the row data to the bulk_data list\n",
    "        bulk_data.append({\n",
    "            'custody_id': custody_id,\n",
    "            'participant_age_group': participant_age_group,\n",
    "            'participant_gender': participant_gender,\n",
    "            'participant_status': participant_status,\n",
    "            'participant_type': participant_type,\n",
    "            'latitude': latitude,\n",
    "            'longitude': longitude,\n",
    "            'gun_stolen': gun_stolen,\n",
    "            'gun_type': gun_type,\n",
    "            'incident_id': incident_id,\n",
    "            'date_fk': date_fk,\n",
    "            # ... other columns ...\n",
    "        })\n",
    "\n",
    "        # Commit in batches\n",
    "        if len(bulk_data) % 1000 == 0:\n",
    "            bulk_insert_data(conn, cursor, 'YourTableName', bulk_data)\n",
    "            bulk_data = []\n",
    "\n",
    "# Commit any remaining records\n",
    "if bulk_data:\n",
    "    bulk_insert_data(conn, cursor, 'YourTableName', bulk_data)\n",
    "\n",
    "# Close the database connection when done\n",
    "cursor.close()\n",
    "conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
